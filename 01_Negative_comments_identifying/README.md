***
Новый сервис предоставляет пользователям возможность редактировать и дополнять описания товаров в интернет-магазине, аналогично вики-сообществам. Этот инструмент позволяет клиентам предлагать правки и комментировать изменения других пользователей. Однако, для обеспечения безопасности и качества контента, магазин нуждается в инструменте, способном автоматически выявлять токсичные комментарии и отправлять их на модерацию.
***

**Цель проекта** — обучить модель, способную классифицировать комментарии на позитивные и негативные. В распоряжении имеется набор данных с разметкой о токсичности правок. Задача заключается в построении модели с уровнем метрики качества F1 не менее 0.75.

!['Схема пайплайна'](https://raw.githubusercontent.com/htoniy/DS_NLP/main/01_Negative_comments_identifying/Project%20Algorithm.png)

***
В работе проведены следующие действия:
- Проведена предобработка исходных текстов в составе:
        1) Лемматезация текста (spaCy).
        2) Удаление стоп слов и служеюных символов (spaCy).
- Добавлены дополнительные признаки по методу TF-IDF (Transform).
- Устранен дисбаланс классов методом upsampling. (imblearn)
- Обучены ряд моделей, с выбором лучших из них, с обучением ансамбля моделей из лучших. Обучены следующие модели:
        1) LogisticalRegressor.
        2) CatBoostClassifier.
        3) LightGBM.
        4) Ансамбль моделей из LinearRegressor, CatBoostClassifier, LightGBM.
        
Лучшей моделью для определения токсичности текста стал ансамбль моделей из LinearRegressor, CatBoostClassifier, LightGBM.

В задаче пороговое значение метрики F1 = 0.75. В проекте удалось достичь значения метрики F1 = 0.787 на тесте, что является очень хорошим результатом для поставленной задачи.

